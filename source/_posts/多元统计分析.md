---
title: 多元统计分析
date: 2024-07-01 00:00:00
categories: CS课程笔记
math: true
---

<!-- toc -->


### 第一章 基本概念

1. **方差的无偏估计，极大似然估计分别是什么？**
   - **无偏估计**：样本方差的无偏估计是为了使估计值的期望等于总体方差。公式为:
     $$ S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2 $$
     其中，$X_i$ 是样本值，$\overline{X}$ 是样本均值，$n$ 是样本量。
   - **极大似然估计**：极大似然估计法通过最大化似然函数来估计参数。对于正态分布的总体方差，极大似然估计公式为:
     $$ \sigma^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2 $$
     其中，$X_i$ 是样本值，$\overline{X}$ 是样本均值，$n$ 是样本量。

2. **样本和总体的常用统计特征是什么？**
   - **样本统计特征**：
     - 样本均值： $\overline{X} = \frac{1}{n} \sum_{i=1}^n X_i$
     - 样本方差： $S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2$
     - 样本标准差： $S = \sqrt{S^2}$
     - 样本中位数： 排序后的中间值
     - 样本偏度和峰度： 衡量数据分布的形状
   - **总体统计特征**：
     - 总体均值： $\mu$
     - 总体方差： $\sigma^2$
     - 总体标准差： $\sigma$
     - 总体中位数： 总体的中间值
     - 总体偏度和峰度： 衡量数据分布的形状


### 第三章 聚类

1. **常用距离计算公式和相关系数计算方法**
   - 欧氏距离: $$ d_{ij} = \sqrt{\sum_{k=1}^n (x_{ik} - x_{jk})^2} $$
   - 曼哈顿距离: $$ d_{ij} = \sum_{k=1}^n |x_{ik} - x_{jk}| $$
   - 余弦相似度: $$ \cos(\theta) = \frac{\sum_{k=1}^n x_{ik} x_{jk}}{\sqrt{\sum_{k=1}^n x_{ik}^2} \sqrt{\sum_{k=1}^n x_{jk}^2}} $$

2. **系统聚类法**: 系统聚类是自底向上的层次聚类方法，通过逐步合并最相似的对象来形成树状结构的分类。原理包括单链法（最近邻）、全链法（最远邻）、平均链法等。

3. **动态聚类k-means原理**: k-means聚类通过迭代优化质心和簇分配，直到收敛。具体步骤包括选择k个初始质心，分配每个点到最近的质心，更新质心位置，重复直到质心不再变化。

4. **系统聚类和动态聚类的异同**: 系统聚类是层次聚类，自底向上构建层次树；动态聚类如k-means是基于质心的划分方法，通过优化质心和簇分配进行聚类。

### 第四章 判别

1. **距离判别，贝叶斯判别，Fisher判别原理和异同**: 距离判别基于距离测量分类；贝叶斯判别基于概率计算分类；Fisher判别通过线性投影优化类间和类内方差之比。

2. **掌握例4.2，4.3，4.4 的计算原理和方法**: 需要详细了解课本中的具体计算例子，掌握其步骤和方法。

3. **掌握Fisher判别的证明原理、方法和计算过程**: Fisher判别分析通过线性投影使得类间方差最大、类内方差最小，其数学推导涉及矩阵代数和特征值问题。

### 第五章 主成分分析

1. **熟悉主成分分析的数学模型，理解和掌握其证明原理和方法（5.3节）**: 主成分分析通过对协方差矩阵的特征值分解，将数据投影到方差最大的方向上进行降维。
   - 数学模型：设数据矩阵为$X$，主成分为$Y = XA$，其中$A$是由特征向量构成的矩阵。
   - 证明原理：通过对协方差矩阵$\Sigma$的特征值分解，找到最大方差方向。

2. **熟悉主成分分析的性质，理解和掌握其证明方法（5.4节，掌握5.4.2中(1)(2)(3)的证明方法，了解(4)(5))**: 主成分分析的性质包括不相关性、最大方差性等。证明方法涉及线性代数和统计学原理。

### 第六章 因子分析

1. **理解因子分析各参数的统计意义，证明过程（6.2.2节）**: 因子分析通过观测变量的线性组合解释潜在因子。参数包括因子载荷、特征值等。

2. **理解因子载荷计算及因子旋转（6.3节，6.4节）**: 因子载荷表示观测变量与潜在因子的相关性；因子旋转用于简化因子结构，使解释更加明确。

3. **掌握因子旋转的原因，定性和定量地说明**: 因子旋转是为了获得更易解释的因子结构，常用方法有正交旋转和斜交旋转。

4. **例子6.1**: 需要掌握课本中的具体计算例子，了解其步骤和方法。

### 第七章 对应分析

1. **理解对应分析和因子分析的异同**: 对应分析用于分类数据，因子分析用于连续数据。

2. **对应分析数学模型及其构造过程（7.2节）**: 对应分析通过行列联表计算独立性，并用特征值分解来表示行列之间的关系。
   - 数学模型：设联表为$N$，标准化后得到矩阵$P = \frac{N}{N_{++}}$ ，其中$N_{++}$是总频数。然后计算标准化矩阵$S$和$T$，得到特征值和特征向量。

3. **对应分析的重要概念(独立性检验必要性，总惯量，对应分析图7.3节)**: 总惯量表示数据的变异程度，对应分析图用二维图形表示行列之间的关系。

4. **结合7.3节、7.4.2节的例子，掌握对应分析计算过程**: 通过计算联表，标准化矩阵，特征值和特征向量，最终绘制对应分析图。

### 第十章 逻辑回归模型

1. **逻辑回归的基本数学模型10.2.2，10.2.3，10.3**: 逻辑回归模型用于分类问题，形式为:
   $$ \log \left( \frac{p}{1-p} \right) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k $$
   其中，$p$是事件发生的概率，$\beta$是回归系数。

2. **理解SIGMOID函数及其本质**: SIGMOID函数将线性回归的输出映射到0到1之间:
   $$ \sigma(x) = \frac{1}{1 + e^{-x}} $$

3. **理解混淆矩阵、accuracy、precision、recall、ROC、KS等评价指标和方法**: 这些指标用于评价分类模型的性能。混淆矩阵显示预测和实际类别的关系；准确率（accuracy）是正确预测的比例；精确率（precision）是正类预测正确的比例；召回率（recall）是正类被正确预测的比例；ROC曲线显示分类器性能；KS统计量衡量分类器区分能力。

### 矩阵分析

主要是向量和矩阵的偏微分和微分。这部分内容参考课件，并结合各章的相关分析和证明学习。